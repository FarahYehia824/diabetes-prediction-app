# -*- coding: utf-8 -*-
"""Copy of Diabets Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b04qpcxdeLbug-8_qhPkebKV3xVQtLnb

# Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.preprocessing import StandardScaler

"""#Exploaring The Data"""

df=pd.read_csv("diabetes.csv")
df.head()

df.shape

df.info()

"""**Dataset Information**

- The dataset contains **768 rows** (patients) and **9 columns** (features + target).
- All columns have **768 non-null values** → no missing values are reported.
- Feature types:
  - **7 integer columns**: `Pregnancies`, `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `Age`, `Outcome`
  - **2 float columns**: `BMI`, `DiabetesPedigreeFunction`
- The target variable is **`Outcome`**:
  - `0` → Non-diabetic  
  - `1` → Diabetic

###Summary Statistics
"""

df.describe().T

"""**Summary of Dataset (Descriptive Statistics)**

- **Pregnancies**: Average ~3.8, with most patients having between 1 and 6 pregnancies. Maximum is 17.  
- **Glucose**: Average ~121. Some records have 0, which is not realistic and likely represents missing data. Most values fall between 99 and 140.  
- **Blood Pressure**: Average ~69. Minimum is 0, which again is unrealistic (likely missing).  
- **Skin Thickness**: Average ~20, but many entries are 0 → possible missing values.  
- **Insulin**: Very skewed. Mean ~80, but some extreme outliers (max = 846). Many 0 values suggest missing data.  
- **BMI**: Average ~32, which indicates obesity on average. Some 0 values are unrealistic (missing).  
- **Diabetes Pedigree Function**: Average ~0.47. Most values are below 1, with a few higher outliers (up to 2.42).  
- **Age**: Average ~33 years, ranging from 21 to 81.  
- **Outcome**: Around 35% of patients are diabetic (Outcome = 1), while 65% are not (Outcome = 0). Slight class imbalance.

####  Missing Values Detection
"""

df.isnull().sum()

(df == 0).sum()

"""**Handling Zero Values (Missing Data)**

From the analysis of zero counts:

- **Columns where 0 is realistic (not missing):**
  - `Pregnancies`: 111 patients with 0 pregnancies (valid).
  - `Outcome`: 500 patients with 0 outcome → means they are **non-diabetic** (valid).
  - `Age` and `DiabetesPedigreeFunction`: no zero values.

- **Columns where 0 is unrealistic (considered missing):**
  - `Glucose` → 5 zeros  
  - `BloodPressure` → 35 zeros  
  - `SkinThickness` → 227 zeros  
  - `Insulin` → 374 zeros  
  - `BMI` → 11 zeros  

👉 These zeros will be treated as **missing values** during preprocessing. We will later replace them (e.g., with median or mean) to improve model performance.

###Outlier Detection using the IQR Method

We applied the Interquartile Range (IQR) method to detect outliers in numerical columns.  
Values outside the calculated lower and upper bounds are considered outliers.  
The table below summarizes the number of outliers and bounds for each column.
"""

numeric_cols = df.select_dtypes(include=['int64','float64']).columns
def detect_outliers_all(data):
    outliers_dict = {}
    for col in numeric_cols :
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        outliers = data[(data[col] < lower) | (data[col] > upper)][col]
        if len(outliers) > 0:
            outliers_dict[col] = {
                "num_outliers": len(outliers),
                "lower_bound": lower,
                "upper_bound": upper
            }
    return outliers_dict

outliers_info = detect_outliers_all(df)
outliers_df = pd.DataFrame(outliers_info).T  # T = transpose
outliers_df = outliers_df.reset_index().rename(columns={'index':'column'})
outliers_df

"""**Outlier Detection Results**

Based on the IQR (Interquartile Range) method, the following outliers were detected:

- **Pregnancies** → 4 outliers (values > 13.5).  
- **Glucose** → 5 outliers (values outside [37.1, 202.1]).  
- **Blood Pressure** → 45 outliers (values outside [35, 107]).  
- **Skin Thickness** → Only 1 outlier (above 80).  
- **Insulin** → 34 outliers (values above 318.1).  
- **BMI** → 19 outliers (values outside [13.3, 50.5]).  
- **Diabetes Pedigree Function** → 29 outliers (values above 1.2).  
- **Age** → 9 outliers (values above 66.5).  

👉 Key Notes:
- Some features like **Insulin** and **Blood Pressure** have a relatively high number of outliers.  
- Outliers may affect model performance, so we need to decide whether to **remove** them or **keep** them depending on domain knowledge.  

"""

import matplotlib.pyplot as plt
import seaborn as sns

# نختار الأعمدة الرقمية بس
numeric_cols = ['Pregnancies', 'Glucose', 'BloodPressure',
                'SkinThickness', 'Insulin', 'BMI',
                'DiabetesPedigreeFunction', 'Age']

plt.figure(figsize=(15, 10))

# نعمل بوكس بلوت لكل الأعمدة
for i, col in enumerate(numeric_cols, 1):
    plt.subplot(3, 3, i)  # نرسمهم في شبكة 3x3
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(col)

plt.tight_layout()
plt.show()

"""### Class Balance (Diabetic vs. Non-Diabetic)

In this section, we check the distribution of the target variable `Outcome` to see how many patients are diabetic (1) and how many are not (0).  
This helps us understand whether the dataset is balanced or imbalanced, which is important for model training.

"""

df['Outcome'].value_counts(normalize=True) * 100

import matplotlib.pyplot as plt

# Count values
outcome_counts = df['Outcome'].value_counts()

# Plot Pie Chart
plt.figure(figsize=(6,6))
plt.pie(outcome_counts, labels=['Non-Diabetic (0)', 'Diabetic (1)'],
        autopct='%1.1f%%', startangle=90, colors=["#8fd9b6", "#ff9999"], explode=(0,0.05))
plt.title("Diabetes Outcome Distribution")
plt.show()

"""**Class Balance Results:**

The results show that:  
- **0 (Non-Diabetic): ~65% of patients**  
- **1 (Diabetic): ~35% of patients**  

This means the dataset is **imbalanced**, with more non-diabetic patients than diabetic ones.  
Although the imbalance is not extreme, it is important to keep in mind during model training, as it may affect the model’s ability to correctly predict diabetic patients.  
Techniques such as resampling (SMOTE, undersampling/oversampling) or using appropriate evaluation metrics (e.g., F1-score, ROC-AUC) might be useful later.

# Data Visualization

###  Glucose vs. Outcome
"""

# Histogram + KDE plot for Glucose by Outcome
plt.figure(figsize=(8,5))

sns.histplot(data=df, x="Glucose", hue="Outcome", kde=True, bins=30, palette="Set2", alpha=0.6)

plt.title("Glucose Levels Distribution by Outcome")
plt.xlabel("Glucose Level")
plt.ylabel("Count")
plt.legend(title="Outcome", labels=["0 = No Diabetes", "1 = Diabetes"])
plt.show()

"""**Glucose Levels vs Outcome**

The plot above shows the distribution of **Glucose levels** for both groups:  
- **Outcome = 0 (No Diabetes):** Most individuals have glucose levels concentrated at lower values.  
- **Outcome = 1 (Diabetes):** Individuals tend to have higher glucose levels compared to the non-diabetic group.  

This confirms that **higher glucose levels are strongly associated with diabetes**.

"""

cols = [ "BMI", "Age", "BloodPressure"]

plt.figure(figsize=(14,10))

for i, col in enumerate(cols, 1):
    plt.subplot(2, 2, i)  # 2 rows, 2 cols
    sns.histplot(data=df, x=col, hue="Outcome", kde=True, bins=30, palette="Set2", alpha=0.6)
    plt.title(f"{col} Distribution by Outcome")
    plt.xlabel(col)
    plt.ylabel("Count")

plt.tight_layout()
plt.show()

"""**Key Features Distribution by Outcome**

The plots above show the distributions of key features for diabetic (Outcome=1) and non-diabetic (Outcome=0) groups:

- **BMI:** People with higher BMI are more likely to have diabetes.  
- **Age:** Older individuals show a higher chance of diabetes compared to younger ones.  
- **BloodPressure:** No clear separation, but slightly higher values are observed for diabetics.

### Pairplot for Key Features
"""

sns.pairplot(df[["Glucose","BMI","Age","Insulin","Outcome"]], hue="Outcome", palette="Set2")
plt.show()

"""**Interpretation of Pairplot**

From the pairplot, we can observe the following:

- **Glucose**: Patients with diabetes (Outcome = 1) tend to have significantly higher glucose levels compared to non-diabetic patients.  
- **BMI**: Higher BMI values are slightly more common among diabetic patients, though the separation is less strong than glucose.  
- **Age**: Diabetic patients are often older than non-diabetic patients, showing age as another influencing factor.  
- **Insulin**: The values are more spread out and less clear, but diabetic patients generally show higher insulin variability.  

📌 Overall, **Glucose** stands out as the strongest feature for distinguishing between diabetic and non-diabetic patients, while **BMI** and **Age** also provide useful signals.

### Correlation Heatmap
"""

plt.figure(figsize=(10,8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Feature Correlation Heatmap")
plt.show()

"""**Correlation Heatmap Interpretation**

The heatmap shows the correlation between all features and the target variable **Outcome** (Diabetes).  

Key insights:  
- **Glucose (0.47)** has the strongest positive correlation with diabetes outcome, making it the most important predictor.  
- **BMI (0.29)** and **Age (0.23)** also show moderate positive correlation with diabetes.  
- **Pregnancies (0.22)** has a noticeable correlation, suggesting higher pregnancies increase diabetes risk.  
- **Insulin (0.13)** and **Diabetes Pedigree Function (0.17)** have weaker but still positive correlations.  
- **BloodPressure (0.06)** and **SkinThickness (0.07)** have very weak correlations with diabetes.  

📌 **Conclusion:** Glucose, BMI, and Age are the most influential features in predicting diabetes, while BloodPressure and SkinThickness contribute less directly.

# Data Pre-processing

#### Handle invalid zero values in specific columns
"""

cols_with_missing = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for col in cols_with_missing:
    median_val = df[col].median()
    df[col] = df[col].replace(0, median_val)

(df==0).sum()

"""### Handling Outliers  

Outliers can negatively affect the model’s performance.  
Here, we handle them using the **IQR method** by capping extreme values.  
We start with the `Insulin` column, which contains many outliers.  

"""

# Handling outliers in the Insulin column using IQR method
Q1 = df['Insulin'].quantile(0.25)
Q3 = df['Insulin'].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

df.loc[df['Insulin'] > upper, "Insulin"] = upper

# After capping
print("\nAfter capping:")
print(df['Insulin'].describe())

columns_to_cap = ['Pregnancies', 'BloodPressure', 'BMI', 'DiabetesPedigreeFunction', 'Age']

for col in columns_to_cap:
    print(f"\nHandling outliers in {col}:")

    # Calculate IQR
    Q1 = df[col].quantile(0.25)
    Q3 = df[col].quantile(0.75)
    IQR = Q3 - Q1

    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR

    # Count outliers before capping
    outliers_count = len(df[(df[col] < lower) | (df[col] > upper)])
    print(f"  Outliers before capping: {outliers_count}")

    # Cap outliers
    df[col] = df[col].clip(lower, upper)

    # Verify no outliers remain
    outliers_after = len(df[(df[col] < lower) | (df[col] > upper)])
    print(f"  Outliers after capping: {outliers_after}")

print("\n✅ All outliers handled successfully!")

"""## Feature Engineering

We will categorize BMI into 4 groups:
- 0: Underweight (<18.5)
- 1: Normal (18.5–24.9)
- 2: Overweight (25–29.9)
- 3: Obese (≥30)

This helps the model capture patterns related to body weight categories.
"""

# BMI Categories
def categorize_bmi(bmi):
    if bmi < 18.5:
        return 0  # Underweight
    elif 18.5 <= bmi < 25:
        return 1  # Normal
    elif 25 <= bmi < 30:
        return 2  # Overweight
    else:
        return 3  # Obese

df['BMI_Category'] = df['BMI'].apply(categorize_bmi)

"""We wll create age groups:
- 0: Young (<30)
- 1: Middle-aged (30–49)
- 2: Older (50+)

Grouping ages helps analyze trends across different life stages.
"""

#  Age Groups
def categorize_age(age):
    if age < 30:
        return 0  # Young
    elif 30 <= age < 50:
        return 1  # Middle-aged
    else:
        return 2  # Older

df['Age_Group'] = df['Age'].apply(categorize_age)

"""We will categorize glucose levels:
- 0: Normal (<100)
- 1: Prediabetic (100–125)
- 2: Diabetic (≥126)

This feature highlights the risk levels associated with diabetes.
"""

# 3. Glucose Categories
def categorize_glucose(glucose):
    if glucose < 100:
        return 0  # Normal
    elif 100 <= glucose < 126:
        return 1  # Prediabetic
    else:
        return 2  # Diabetic range

df['Glucose_Category'] = df['Glucose'].apply(categorize_glucose)

# Display the current dataset shape
print(f"Dataset shape after your preprocessing: {df.shape}")
print(f"New features added: BMI_Category, Age_Group, Glucose_Category")

"""#Model Building"""

# Separate features (X) and target (y)
X = df.drop('Outcome', axis=1)  # All features except target
y = df['Outcome']               # Target variable

"""#####Handle Class Imbalance"""

print("\n=== STEP 2: Handle Class Imbalance ===")

from imblearn.over_sampling import SMOTE
from collections import Counter

print("Class distribution before SMOTE:")
original_distribution = Counter(y)
print(f"Class 0 (No Diabetes): {original_distribution[0]} ({original_distribution[0]/len(y)*100:.1f}%)")
print(f"Class 1 (Diabetes): {original_distribution[1]} ({original_distribution[1]/len(y)*100:.1f}%)")

# Apply SMOTE to balance the classes
smote = SMOTE(random_state=42, sampling_strategy='auto')
X_balanced, y_balanced = smote.fit_resample(X, y)

print("\nClass distribution after SMOTE:")
balanced_distribution = Counter(y_balanced)
print(f"Class 0 (No Diabetes): {balanced_distribution[0]} ({balanced_distribution[0]/len(y_balanced)*100:.1f}%)")
print(f"Class 1 (Diabetes): {balanced_distribution[1]} ({balanced_distribution[1]/len(y_balanced)*100:.1f}%)")

print(f"Dataset shape after SMOTE: {X_balanced.shape}")

"""#####Train/Test Split"""

from sklearn.model_selection import train_test_split

# Split the balanced data
X_train, X_test, y_train, y_test = train_test_split(
    X_balanced, y_balanced,
    test_size=0.2,
    random_state=42,
    stratify=y_balanced
)

print(f"Training set: {X_train.shape}")
print(f"Test set: {X_test.shape}")
print(f"Training target distribution: {Counter(y_train)}")
print(f"Test target distribution: {Counter(y_test)}")

"""#####Feature Scaling"""

from sklearn.preprocessing import StandardScaler

# Initialize and fit the scaler on training data
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)  # Only transform test data

print("✅ Features scaled using StandardScaler")
print(f"Scaled training features shape: {X_train_scaled.shape}")
print(f"Scaled test features shape: {X_test_scaled.shape}")

"""##Model Training and Evaluation

"""

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, roc_auc_score
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

def extended_model_competition(X_train, X_test, y_train, y_test):


    print("🚀 Extended Model Competition Starting...")

    models_config = {
        'Logistic Regression': {
            'model': LogisticRegression(random_state=42, max_iter=1000),
            'params': {
                'C': [0.01, 0.1, 1, 10, 100],
                'penalty': ['l1', 'l2'],
                'solver': ['liblinear']
            }
        },

        'KNN': {
            'model': KNeighborsClassifier(),
            'params': {
                'n_neighbors': [3, 5, 7, 9, 11],
                'weights': ['uniform', 'distance'],
                'metric': ['euclidean', 'manhattan']
            }
        },

        'SVM': {
            'model': SVC(random_state=42, probability=True),
            'params': {
                'C': [0.01, 0.1, 1, 10, 15, 20],
                'gamma': [0.0001, 0.001, 0.01, 0.1, 1],
                'kernel': ['rbf', 'linear']
            }
        },

        'Decision Tree': {
            'model': DecisionTreeClassifier(random_state=42),
            'params': {
                'criterion': ['gini', 'entropy'],
                'max_depth': [3, 5, 7, 10, None],
                'min_samples_split': [2, 3, 5, 7],
                'min_samples_leaf': [1, 2, 3, 5]
            }
        },

        'Random Forest': {
            'model': RandomForestClassifier(random_state=42),
            'params': {
                'n_estimators': [100, 130, 150, 200],
                'max_depth': [10, 15, 20, None],
                'min_samples_split': [2, 3, 5],
                'min_samples_leaf': [1, 2, 3],
                'criterion': ['gini', 'entropy']
            }
        },

        'Gradient Boosting': {
            'model': GradientBoostingClassifier(random_state=42),
            'params': {
                'n_estimators': [100, 150, 180, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7],
                'loss': ['deviance', 'exponential']
            }
        },

        'XGBoost': {
            'model': XGBClassifier(random_state=42, objective='binary:logistic'),
            'params': {
                'n_estimators': [100, 150, 180, 200],
                'learning_rate': [0.01, 0.1, 0.2],
                'max_depth': [3, 5, 7, 10],
                'subsample': [0.8, 0.9, 1.0]
            }
        }
    }

    results = {}

    for model_name, config in models_config.items():
        print(f"\n🤖 Training {model_name}...")

        # Use smaller parameter grids for faster execution
        if model_name in ['SVM', 'Decision Tree']:
            cv_folds = 3
        else:
            cv_folds = 5

        grid_search = GridSearchCV(
            estimator=config['model'],
            param_grid=config['params'],
            cv=cv_folds,
            scoring='roc_auc',
            n_jobs=-1,
            verbose=0
        )

        grid_search.fit(X_train, y_train)

        # Predictions
        y_pred = grid_search.predict(X_test)
        y_pred_proba = grid_search.predict_proba(X_test)[:, 1]

        # Metrics
        test_accuracy = accuracy_score(y_test, y_pred)
        test_auc = roc_auc_score(y_test, y_pred_proba)

        results[model_name] = {
            'model': grid_search.best_estimator_,
            'best_params': grid_search.best_params_,
            'cv_score': grid_search.best_score_,
            'test_accuracy': test_accuracy,
            'test_auc': test_auc,
            'predictions': y_pred,
            'probabilities': y_pred_proba
        }

        print(f"   ✅ Test Accuracy: {test_accuracy:.4f}")
        print(f"   ✅ Test AUC: {test_auc:.4f}")

    # Results DataFrame
    results_df = pd.DataFrame({
        'Model': list(results.keys()),
        'CV_AUC': [results[m]['cv_score'] for m in results.keys()],
        'Test_Accuracy': [results[m]['test_accuracy'] for m in results.keys()],
        'Test_AUC': [results[m]['test_auc'] for m in results.keys()]
    }).sort_values('Test_AUC', ascending=False)

    print(f"\n🏆 FINAL RESULTS:")
    print("="*60)
    print(results_df.to_string(index=False))

    return results, results_df

def plot_extended_comparison(results_df):
    """
    Plot comparison of all models
    """
    models = results_df['Model'].values
    accuracy = results_df['Test_Accuracy'].values * 100  # Convert to percentage
    auc = results_df['Test_AUC'].values * 100

    x = np.arange(len(models))
    width = 0.35

    fig, ax = plt.subplots(figsize=(15, 8))

    bars1 = ax.bar(x - width/2, accuracy, width, label='Accuracy (%)',
                   alpha=0.8, color='mediumpurple')
    bars2 = ax.bar(x + width/2, auc, width, label='AUC (%)',
                   alpha=0.8, color='rebeccapurple')

    ax.set_xlabel('Models', fontsize=12)
    ax.set_ylabel('Score (%)', fontsize=12)
    ax.set_title('Extended Model Performance Comparison - Diabetes Prediction', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(models, rotation=45, ha='right')
    ax.legend()
    ax.grid(True, alpha=0.3)

    # Add value labels on bars
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{height:.1f}%', ha='center', va='bottom', fontsize=10)

    plt.ylim([70, 100])
    plt.tight_layout()
    plt.show()

# Run extended competition
extended_results, extended_results_df = extended_model_competition(
    X_train_scaled, X_test_scaled, y_train, y_test
)

# Plot results
plot_extended_comparison(extended_results_df)

# Show best parameters for top 3 models
print(f"\n🔧 BEST PARAMETERS FOR TOP 3 MODELS:")
print("="*60)
for i, (_, row) in enumerate(extended_results_df.head(3).iterrows()):
    model_name = row['Model']
    best_params = extended_results[model_name]['best_params']
    print(f"\n{i+1}. {model_name}:")
    for param, value in best_params.items():
        print(f"   • {param}: {value}")

import joblib

# Save best model
best_model = extended_results[extended_results_df.iloc[0]['Model']]['model']
joblib.dump(best_model, 'diabetes_model.pkl')

# Save scaler
joblib.dump(scaler, 'diabetes_scaler.pkl')

print("✅ Model and scaler saved!")

"""## 🩺 Diabetes Prediction Engine - Final Deployment

Now let's create a simple prediction function using your trained model:
"""

def predict_diabetes_simple():
    print("🩺 Diabetes Predictor")
    print("="*30)

    pregnancies = int(input("Pregnancies (0-20): "))
    glucose = float(input("Glucose (70-200): "))
    blood_pressure = float(input("Blood Pressure (40-130): "))
    skin_thickness = float(input("Skin Thickness (10-99): "))
    insulin = float(input("Insulin (0-850): "))
    bmi = float(input("BMI (15-70): "))
    diabetes_pedigree = float(input("Diabetes Pedigree (0.0-2.5): "))
    age = int(input("Age (18-100): "))

    # Get best model from your training results
    best_model = extended_results[extended_results_df.iloc[0]['Model']]['model']

    # Create features
    bmi_cat = 3 if bmi >= 30 else 2 if bmi >= 25 else 1 if bmi >= 18.5 else 0
    age_group = 2 if age >= 50 else 1 if age >= 30 else 0
    glucose_cat = 2 if glucose >= 126 else 1 if glucose >= 100 else 0

    input_data = pd.DataFrame([[pregnancies, glucose, blood_pressure, skin_thickness,
                               insulin, bmi, diabetes_pedigree, age,
                               bmi_cat, age_group, glucose_cat]],
                             columns=['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',
                                    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age',
                                    'BMI_Category', 'Age_Group', 'Glucose_Category'])

    input_scaled = scaler.transform(input_data)
    prediction = best_model.predict(input_scaled)[0]
    probability = best_model.predict_proba(input_scaled)[0][1]

    result = "🔴 DIABETIC" if prediction == 1 else "✅ NOT DIABETIC"

    print("="*40)
    print(f"PREDICTION: {result}")
    print(f"Risk: {probability:.1%}")
    print("="*40)

    return result

# Use it:
predict_diabetes_simple()

"""# Deployment with Streamlit"""

import streamlit as st

st.title("My First Streamlit App")
st.write("Hello, this is my project!")